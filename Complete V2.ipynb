{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcc7e15",
   "metadata": {},
   "source": [
    "speech_to_text_en >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e690289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Loading Whisper STT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Whisper model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "import warnings\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# ----------------\n",
    "# Suppress warnings\n",
    "# ----------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------\n",
    "# Device & dtype\n",
    "# ----------------\n",
    "_DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "_DTYPE = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# ----------------\n",
    "# Load model ONCE\n",
    "# ----------------\n",
    "print(\"üéôÔ∏è Loading Whisper STT model...\")\n",
    "_stt_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v3\",\n",
    "    torch_dtype=_DTYPE,\n",
    "    device=_DEVICE,\n",
    ")\n",
    "print(\"‚úÖ Whisper model loaded\")\n",
    "\n",
    "\n",
    "def speech_to_text_en(audio_path: str, language: str = \"english\") -> str:\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏∂‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á TypeError\n",
    "    \"\"\"\n",
    "    temp_audio = \"temp_whisper_input.wav\"\n",
    "    \n",
    "    try:\n",
    "        # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        if audio_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            print(f\"üé¨ Extracting audio from: {audio_path}\")\n",
    "            video = VideoFileClip(audio_path)\n",
    "            \n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°\n",
    "            if video.audio is None:\n",
    "                video.close()\n",
    "                return \"\" # ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞ raise Error ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "            \n",
    "            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô .wav (16kHz, Mono ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà Whisper ‡∏ä‡∏≠‡∏ö)\n",
    "            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á TypeError: arrays to stack... ‡πÑ‡∏î‡πâ 100%\n",
    "            video.audio.write_audiofile(\n",
    "                temp_audio, \n",
    "                fps=16000, \n",
    "                nbytes=2, \n",
    "                codec='pcm_s16le', \n",
    "                verbose=False, \n",
    "                logger=None\n",
    "            )\n",
    "            video.close()\n",
    "            path_to_process = temp_audio\n",
    "        else:\n",
    "            path_to_process = audio_path\n",
    "\n",
    "        # 2. ‡∏™‡πà‡∏á Path ‡πÉ‡∏´‡πâ Pipeline (Whisper ‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ FFmpeg)\n",
    "        print(\"üéôÔ∏è Transcribing...\")\n",
    "        result = _stt_pipe(\n",
    "            path_to_process,\n",
    "            chunk_length_s=30,\n",
    "            generate_kwargs={\"language\": \"english\",\"return_timestamps\": True}\n",
    "        )\n",
    "\n",
    "        # 3. ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß\n",
    "        if os.path.exists(temp_audio):\n",
    "            os.remove(temp_audio)\n",
    "\n",
    "        return result[\"text\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        # ‡∏Å‡∏£‡∏ì‡∏µ Error ‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏¥‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢\n",
    "        if os.path.exists(temp_audio):\n",
    "            os.remove(temp_audio)\n",
    "        print(f\"‚ùå Error during STT: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd31ec",
   "metadata": {},
   "source": [
    "text_translation >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3165b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:18<00:00,  9.42s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"‡πÅ‡∏õ‡∏• Text ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô Text ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\"\"\"\n",
    "\n",
    "\"\"\"‡πÅ‡∏õ‡∏•‡∏á Text ‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ó‡∏¢\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "#‡πÇ‡∏´‡∏•‡∏î Model\n",
    "model_id = \"scb10x/typhoon-translate-4b\"\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î Tokenizer ‡πÅ‡∏•‡∏∞ Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "model_id, \n",
    "torch_dtype=torch.bfloat16, \n",
    "device_map={\"\": 0}, #‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ GPU\n",
    ")\n",
    "  \n",
    "def text_translation(ENG_text_path):\n",
    "    #‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•\n",
    "    text = ENG_text_path\n",
    "\n",
    "\n",
    "    # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ System Prompt ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "    messages3 = [\n",
    "        {\"role\": \"system\", \"content\": \"Translate the following text into Thai.\"},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Input\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "    messages3, \n",
    "    add_generation_prompt=True, \n",
    "    return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    \n",
    "        # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Generate ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    outputs = model.generate(\n",
    "        input_ids, \n",
    "        max_new_tokens=512, \n",
    "        do_sample=False, # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏¥‡∏î sampling ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•\n",
    "        temperature=None, # ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏Å\n",
    "        top_p=None\n",
    "    )\n",
    "    TH_text = tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True)\n",
    "    return TH_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73651632",
   "metadata": {},
   "source": [
    "text_to_speech_TH >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43d8a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîä Loading MMS-TTS-THAI model...\n",
      "‚úÖ MMS-TTS model loaded\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# MMS-TTS (Standard TTS)\n",
    "# -----------------------------\n",
    "import torch\n",
    "import scipy.io.wavfile as wavfile\n",
    "from transformers import VitsModel, AutoTokenizer\n",
    "\n",
    "print(\"üîä Loading MMS-TTS-THAI model...\")\n",
    "_mms_model_name = \"facebook/mms-tts-tha\"\n",
    "_mms_model = VitsModel.from_pretrained(_mms_model_name)\n",
    "_mms_tokenizer = AutoTokenizer.from_pretrained(_mms_model_name)\n",
    "print(\"‚úÖ MMS-TTS model loaded\")\n",
    "\n",
    "\n",
    "\n",
    "def text_to_speech_TH(text: str, output_path: str = \"thai_mms.wav\"):\n",
    "    try:\n",
    "        inputs = _mms_tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            waveform = _mms_model(**inputs).waveform\n",
    "\n",
    "        sample_rate = _mms_model.config.sampling_rate\n",
    "\n",
    "        wavfile.write(\n",
    "            output_path,\n",
    "            rate=sample_rate,\n",
    "            data=waveform[0].cpu().numpy(),\n",
    "        )\n",
    "        # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á return dictionary ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏Ñ‡πà‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ö‡∏≠‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Å‡πá‡πÑ‡∏î‡πâ)\n",
    "        print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î Error ‡∏Å‡πá‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö\n",
    "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9af79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from moviepy.audio.fx.all import audio_loop\n",
    "\n",
    "def video_sound_editor(new_sound_path, video_path, output_path):\n",
    "    \"\"\"\n",
    "    ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏î‡∏¥‡∏° \n",
    "    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤: ‡∏à‡∏∞‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Loop)\n",
    "    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡∏à‡∏∞‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ (Trim)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á\n",
    "        video = VideoFileClip(video_path)\n",
    "        new_audio = AudioFileClip(new_sound_path)\n",
    "\n",
    "        # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "        if new_audio.duration < video.duration:\n",
    "            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤: ‡πÉ‡∏´‡πâ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏ô‡∏à‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            print(f\"üîÑ Audio is shorter than video. Looping audio...\")\n",
    "            final_audio = audio_loop(new_audio, duration=video.duration)\n",
    "        else:\n",
    "            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            print(f\"‚úÇÔ∏è Audio is longer than video. Trimming audio...\")\n",
    "            final_audio = new_audio.subclip(0, video.duration)\n",
    "\n",
    "        # 3. ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏î‡∏¥‡∏°\n",
    "        final_video = video.set_audio(final_audio)\n",
    "\n",
    "        # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        print(f\"üíæ Exporting video to: {output_path}\")\n",
    "        final_video.write_videofile(\n",
    "            output_path,\n",
    "            fps=video.fps,           # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ fps ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            codec=\"libx264\",         # ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            audio_codec=\"aac\",       # ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "            audio=True,              # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ó‡∏£‡πá‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "            temp_audiofile='temp-audio-final.m4a',\n",
    "            remove_temp=True\n",
    "        )\n",
    "\n",
    "        # 5. ‡∏õ‡∏¥‡∏î Resource (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å Lock)\n",
    "        video.close()\n",
    "        new_audio.close()\n",
    "        final_audio.close()\n",
    "        final_video.close()\n",
    "        \n",
    "        print(\"‚úÖ Video processing completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in video_sound_editor: {e}\")\n",
    "        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏õ‡∏¥‡∏î Resource ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î Error\n",
    "        if 'video' in locals(): video.close()\n",
    "        if 'new_audio' in locals(): new_audio.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832c045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import customtkinter as ctk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Theme ‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢\n",
    "ctk.set_appearance_mode(\"System\")  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° Windows (Light/Dark)\n",
    "ctk.set_default_color_theme(\"blue\")\n",
    "\n",
    "def show_modern_msg(title, message):\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö Modern\"\"\"\n",
    "    msg_window = ctk.CTkToplevel()\n",
    "    msg_window.title(title)\n",
    "    msg_window.geometry(\"350150\")\n",
    "    msg_window.attributes('-topmost', True)\n",
    "    \n",
    "    # ‡∏ß‡∏≤‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏≤‡∏á‡∏à‡∏≠\n",
    "    msg_window.update_idletasks()\n",
    "    x = (msg_window.winfo_screenwidth() // 2) - (msg_window.winfo_width() // 2)\n",
    "    y = (msg_window.winfo_screenheight() // 2) - (msg_window.winfo_height() // 2)\n",
    "    msg_window.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "    label = ctk.CTkLabel(msg_window, text=message, font=(\"Leelawadee UI\", 14), wraplength=300)\n",
    "    label.pack(expand=True, padx=20, pady=20)\n",
    "\n",
    "    btn = ctk.CTkButton(msg_window, text=\"‡∏ï‡∏Å‡∏•‡∏á\", command=msg_window.destroy, width=100)\n",
    "    btn.pack(pady=(0, 20))\n",
    "    \n",
    "    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ User ‡∏Å‡∏î‡∏ï‡∏Å‡∏•‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ï‡πà‡∏≠ (Optional)\n",
    "    msg_window.grab_set() \n",
    "    msg_window.wait_window()\n",
    "\n",
    "def processing_pipline():\n",
    "    root = ctk.CTk()\n",
    "    root.withdraw()\n",
    "\n",
    "    # 1. ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å\n",
    "    show_modern_msg(\"‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°\", \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö ‚ú®\")\n",
    "    \n",
    "    original_video_path = filedialog.askopenfilename(\n",
    "        title=\"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\",\n",
    "        filetypes=[(\"Video\", \"*.mp4 *.avi *.mkv\")]\n",
    "    )\n",
    "\n",
    "    if not original_video_path: return\n",
    "\n",
    "    # [ ... ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ... ]\n",
    "    base_dir = os.path.dirname(original_video_path)\n",
    "    sound_path = os.path.join(base_dir, \"translated_audio.wav\")\n",
    "    \n",
    "    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\n",
    "    eng_text = speech_to_text_en(original_video_path)\n",
    "    th_text = text_translation(eng_text)\n",
    "    text_to_speech_TH(th_text, sound_path)\n",
    "\n",
    "    # 2. ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á (‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•)\n",
    "    show_modern_msg(\"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\", \"‡πÄ‡∏£‡∏≤‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö\\n‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\")\n",
    "\n",
    "    final_output_path = filedialog.asksaveasfilename(\n",
    "        title=\"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\",\n",
    "        defaultextension=\".mp4\",\n",
    "        initialfile=\"video_TH.mp4\"\n",
    "    )\n",
    "\n",
    "    if final_output_path:\n",
    "        video_sound_editor(sound_path, original_video_path, final_output_path)\n",
    "        show_modern_msg(\"‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\", \"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÑ‡∏ó‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö üéâ\")\n",
    "        \n",
    "        if os.path.exists(sound_path):\n",
    "            os.remove(sound_path)\n",
    "\n",
    "    root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fd41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Extracting audio from: C:/Users/Napat/Downloads/danmachi.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: C:/Users/Napat/Downloads\\translated_audio.wav\n",
      "‚úÇÔ∏è Audio is longer than video. Trimming audio...\n",
      "üíæ Exporting video to: C:/Users/Napat/Downloads/video_TH.mp4\n",
      "Moviepy - Building video C:/Users/Napat/Downloads/video_TH.mp4.\n",
      "MoviePy - Writing audio in temp-audio-final.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video C:/Users/Napat/Downloads/video_TH.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:/Users/Napat/Downloads/video_TH.mp4\n",
      "‚úÖ Video processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "processing_pipline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team_Prject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

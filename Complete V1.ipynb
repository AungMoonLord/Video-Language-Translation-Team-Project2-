{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795a60b6",
   "metadata": {},
   "source": [
    "speech_to_text_en >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676289e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Loading Whisper STT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Whisper model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "import warnings\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# ----------------\n",
    "# Suppress warnings\n",
    "# ----------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------\n",
    "# Device & dtype\n",
    "# ----------------\n",
    "_DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "_DTYPE = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# ----------------\n",
    "# Load model ONCE\n",
    "# ----------------\n",
    "print(\"üéôÔ∏è Loading Whisper STT model...\")\n",
    "_stt_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v3\",\n",
    "    torch_dtype=_DTYPE,\n",
    "    device=_DEVICE,\n",
    ")\n",
    "print(\"‚úÖ Whisper model loaded\")\n",
    "\n",
    "\n",
    "def speech_to_text_en(audio_path: str, language: str = \"english\") -> str:\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏∂‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á TypeError\n",
    "    \"\"\"\n",
    "    temp_audio = \"temp_whisper_input.wav\"\n",
    "    \n",
    "    try:\n",
    "        # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        if audio_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            print(f\"üé¨ Extracting audio from: {audio_path}\")\n",
    "            video = VideoFileClip(audio_path)\n",
    "            \n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°\n",
    "            if video.audio is None:\n",
    "                video.close()\n",
    "                return \"\" # ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞ raise Error ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "            \n",
    "            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô .wav (16kHz, Mono ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà Whisper ‡∏ä‡∏≠‡∏ö)\n",
    "            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á TypeError: arrays to stack... ‡πÑ‡∏î‡πâ 100%\n",
    "            video.audio.write_audiofile(\n",
    "                temp_audio, \n",
    "                fps=16000, \n",
    "                nbytes=2, \n",
    "                codec='pcm_s16le', \n",
    "                verbose=False, \n",
    "                logger=None\n",
    "            )\n",
    "            video.close()\n",
    "            path_to_process = temp_audio\n",
    "        else:\n",
    "            path_to_process = audio_path\n",
    "\n",
    "        # 2. ‡∏™‡πà‡∏á Path ‡πÉ‡∏´‡πâ Pipeline (Whisper ‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ FFmpeg)\n",
    "        print(\"üéôÔ∏è Transcribing...\")\n",
    "        result = _stt_pipe(\n",
    "            path_to_process,\n",
    "            chunk_length_s=30,\n",
    "            generate_kwargs={\"language\": \"english\",\"return_timestamps\": True}\n",
    "        )\n",
    "\n",
    "        # 3. ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß\n",
    "        if os.path.exists(temp_audio):\n",
    "            os.remove(temp_audio)\n",
    "\n",
    "        return result[\"text\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        # ‡∏Å‡∏£‡∏ì‡∏µ Error ‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏¥‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢\n",
    "        if os.path.exists(temp_audio):\n",
    "            os.remove(temp_audio)\n",
    "        print(f\"‚ùå Error during STT: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ef3f8",
   "metadata": {},
   "source": [
    "text_translation >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31c699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [02:46<00:00, 83.34s/it] \n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:18<00:00,  9.18s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"‡πÅ‡∏õ‡∏• Text ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô Text ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\"\"\"\n",
    "\n",
    "\"\"\"‡πÅ‡∏õ‡∏•‡∏á Text ‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ó‡∏¢\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "#‡πÇ‡∏´‡∏•‡∏î Model\n",
    "model_id = \"scb10x/typhoon-translate-4b\"\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î Tokenizer ‡πÅ‡∏•‡∏∞ Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "model_id, \n",
    "torch_dtype=torch.bfloat16, \n",
    "device_map={\"\": 0}, #‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ GPU\n",
    ")\n",
    "  \n",
    "def text_translation(ENG_text_path):\n",
    "    #‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•\n",
    "    text = ENG_text_path\n",
    "\n",
    "\n",
    "    # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ System Prompt ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "    messages3 = [\n",
    "        {\"role\": \"system\", \"content\": \"Translate the following text into Thai.\"},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Input\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "    messages3, \n",
    "    add_generation_prompt=True, \n",
    "    return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    \n",
    "        # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Generate ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    outputs = model.generate(\n",
    "        input_ids, \n",
    "        max_new_tokens=512, \n",
    "        do_sample=False, # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏¥‡∏î sampling ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•\n",
    "        temperature=None, # ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏Å\n",
    "        top_p=None\n",
    "    )\n",
    "    TH_text = tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True)\n",
    "    return TH_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f797ebf",
   "metadata": {},
   "source": [
    "text_to_speech_TH >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864d2980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîä Loading MMS-TTS-THAI model...\n",
      "‚úÖ MMS-TTS model loaded\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# MMS-TTS (Standard TTS)\n",
    "# -----------------------------\n",
    "import torch\n",
    "import scipy.io.wavfile as wavfile\n",
    "from transformers import VitsModel, AutoTokenizer\n",
    "\n",
    "print(\"üîä Loading MMS-TTS-THAI model...\")\n",
    "_mms_model_name = \"facebook/mms-tts-tha\"\n",
    "_mms_model = VitsModel.from_pretrained(_mms_model_name)\n",
    "_mms_tokenizer = AutoTokenizer.from_pretrained(_mms_model_name)\n",
    "print(\"‚úÖ MMS-TTS model loaded\")\n",
    "\n",
    "\n",
    "def text_to_speech_TH(\n",
    "    text: str,\n",
    "    output_path: str = \"thai_mms.wav\",\n",
    "):\n",
    "\n",
    "    try:\n",
    "        inputs = _mms_tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            waveform = _mms_model(**inputs).waveform\n",
    "\n",
    "        sample_rate = _mms_model.config.sampling_rate\n",
    "\n",
    "        wavfile.write(\n",
    "            output_path,\n",
    "            rate=sample_rate,\n",
    "            data=waveform[0].cpu().numpy(),\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"audio_path\": output_path,\n",
    "            \"sample_rate\": sample_rate,\n",
    "            \"error\": None,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"audio_path\": None,\n",
    "            \"sample_rate\": None,\n",
    "            \"error\": str(e),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3005f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from moviepy.audio.fx.all import audio_loop\n",
    "\n",
    "def video_sound_editor(new_sound_path, video_path, output_path):\n",
    "    \"\"\"\n",
    "    ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏î‡∏¥‡∏° \n",
    "    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤: ‡∏à‡∏∞‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Loop)\n",
    "    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡∏à‡∏∞‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ (Trim)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á\n",
    "        video = VideoFileClip(video_path)\n",
    "        new_audio = AudioFileClip(new_sound_path)\n",
    "\n",
    "        # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "        if new_audio.duration < video.duration:\n",
    "            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤: ‡πÉ‡∏´‡πâ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏ô‡∏à‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            print(f\"üîÑ Audio is shorter than video. Looping audio...\")\n",
    "            final_audio = audio_loop(new_audio, duration=video.duration)\n",
    "        else:\n",
    "            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            print(f\"‚úÇÔ∏è Audio is longer than video. Trimming audio...\")\n",
    "            final_audio = new_audio.subclip(0, video.duration)\n",
    "\n",
    "        # 3. ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏î‡∏¥‡∏°\n",
    "        final_video = video.set_audio(final_audio)\n",
    "\n",
    "        # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        print(f\"üíæ Exporting video to: {output_path}\")\n",
    "        final_video.write_videofile(\n",
    "            output_path,\n",
    "            fps=video.fps,           # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ fps ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            codec=\"libx264\",         # ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "            audio_codec=\"aac\",       # ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "            audio=True,              # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ó‡∏£‡πá‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "            temp_audiofile='temp-audio-final.m4a',\n",
    "            remove_temp=True\n",
    "        )\n",
    "\n",
    "        # 5. ‡∏õ‡∏¥‡∏î Resource (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å Lock)\n",
    "        video.close()\n",
    "        new_audio.close()\n",
    "        final_audio.close()\n",
    "        final_video.close()\n",
    "        \n",
    "        print(\"‚úÖ Video processing completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in video_sound_editor: {e}\")\n",
    "        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏õ‡∏¥‡∏î Resource ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î Error\n",
    "        if 'video' in locals(): video.close()\n",
    "        if 'new_audio' in locals(): new_audio.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_pipline():\n",
    "    original_video_path = \"C:\\Users\\Napat\\Downloads\\danmachi.mp4\"\n",
    "    \n",
    "    eng_text = speech_to_text_en(original_video_path)\n",
    "    th_text = text_translation(eng_text)\n",
    "\n",
    "    # Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\n",
    "    sound_path = \"D:/Implementation/Data/translated_audio.wav\"\n",
    "\n",
    "    dummy = text_to_speech_TH(th_text,sound_path)\n",
    "\n",
    "    # Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Video ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏£‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ\n",
    "    translated_video_path = \"D:/Implementation/Data/danmachi.mp4\"\n",
    "    \n",
    "    final_output_path = \"D:/Implementation/Data/danmachi_TH.mp4\"\n",
    "    video_sound_editor(sound_path,translated_video_path,final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ad9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Extracting audio from: D:/Implementation/Data/danmachi.mp4\n",
      "‚ùå Error during STT: MoviePy error: the file D:/Implementation/Data/danmachi.mp4 could not be found!\n",
      "Please check that you entered the correct path.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "MoviePy error: the file D:/Implementation/Data/danmachi.mp4 could not be found!\nPlease check that you entered the correct path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocessing_pipline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mprocessing_pipline\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocessing_pipline\u001b[39m():\n\u001b[0;32m      2\u001b[0m     original_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/Implementation/Data/danmachi.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     eng_text \u001b[38;5;241m=\u001b[39m \u001b[43mspeech_to_text_en\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_video_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     th_text \u001b[38;5;241m=\u001b[39m text_translation(eng_text)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 82\u001b[0m, in \u001b[0;36mspeech_to_text_en\u001b[1;34m(audio_path, language)\u001b[0m\n\u001b[0;32m     80\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(temp_audio)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Error during STT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m, in \u001b[0;36mspeech_to_text_en\u001b[1;34m(audio_path, language)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mov\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müé¨ Extracting audio from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     video \u001b[38;5;241m=\u001b[39m \u001b[43mVideoFileClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m video\u001b[38;5;241m.\u001b[39maudio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Napat\\anaconda3\\envs\\Team_Prject2\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Make a reader\u001b[39;00m\n\u001b[0;32m     87\u001b[0m pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m \u001b[43mFFMPEG_VideoReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_fmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpix_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mresize_algo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mduration\n",
      "File \u001b[1;32mc:\\Users\\Napat\\anaconda3\\envs\\Team_Prject2\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_parse_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_duration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_fps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Napat\\anaconda3\\envs\\Team_Prject2\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:270\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    268\u001b[0m lines \u001b[38;5;241m=\u001b[39m infos\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoviePy error: the file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m could not be found!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that you entered the correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m%\u001b[39mfilename)\n\u001b[0;32m    274\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# get duration (in seconds)\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: MoviePy error: the file D:/Implementation/Data/danmachi.mp4 could not be found!\nPlease check that you entered the correct path."
     ]
    }
   ],
   "source": [
    "processing_pipline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team_Prject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

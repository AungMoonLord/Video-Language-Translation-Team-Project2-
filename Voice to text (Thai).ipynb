{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35591db2",
   "metadata": {},
   "source": [
    "à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥ scb10x/typhoon-asr-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84daae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aungl\\anaconda3\\envs\\Team_Project2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2025-12-07 00:02:34 megatron_init:62] Megatron num_microbatches_calculator not found, using Apex version.\n",
      "W1207 00:02:34.304000 16924 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.\n",
      "No exporters were provided. This means that no telemetry data will be collected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒªï¸ Loading Typhoon ASR model on CUDA...\n",
      "[NeMo I 2025-12-07 00:02:38 mixins:184] Tokenizer SentencePieceTokenizer initialized with 2048 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-12-07 00:02:39 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/stt_th_conformer_transducer_large/prepare_data/typhoon_cleanser/20250814/Split_gg/train_data_typhoon_asr_realtime.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 30.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-12-07 00:02:39 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/data/scbx_testset_manifest.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    max_duration: 30.0\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    \n",
      "[NeMo W 2025-12-07 00:02:39 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-12-07 00:02:39 features:306] PADDING: 0\n",
      "[NeMo I 2025-12-07 00:02:41 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:41 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:41 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:41 save_restore_connector:284] Model EncDecRNNTBPEModel was successfully restored from C:\\Users\\aungl\\.cache\\huggingface\\hub\\models--scb10x--typhoon-asr-realtime\\snapshots\\a14b79d50c788dbdfe559c8a28a9b90153cf3865\\typhoon-asr-realtime.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-12-07 00:02:43 dataloader:743] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token\n",
      "[NeMo W 2025-12-07 00:02:43 dataloader:488] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ™ï¸ Running basic transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸–à¸­à¸”à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸šà¸œà¸¡à¸Šà¸·à¹ˆà¸­à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸ à¸§à¸“à¸´à¸Šà¸Šà¸™à¸±à¸¢ à¸£à¸«à¸±à¸ªà¸«à¸à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¸ªà¸­à¸‡à¹€à¸à¹‰à¸²à¹€à¸ˆà¹‡à¸” à¹€à¸­à¹ˆà¸­ à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œ à¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡à¹€à¸à¹‰à¸² à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸—à¸«à¸²à¸£à¸£à¸²à¸Šà¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n",
      "à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: 0.89 à¸§à¸´à¸™à¸²à¸—à¸µ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typhoon_asr import transcribe\n",
    "\n",
    "# à¹à¸—à¸™à¸—à¸µà¹ˆ 'path/to/your_audio.wav' à¸”à¹‰à¸§à¸¢à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸‚à¸­à¸‡à¸„à¸¸à¸“\n",
    "# à¸£à¸­à¸‡à¸£à¸±à¸šà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸«à¸¥à¸²à¸¢à¸£à¸¹à¸›à¹à¸šà¸š à¹€à¸Šà¹ˆà¸™ ['.wav', '.mp3', '.flac', '.ogg']\n",
    "audio_file_path = \"Aung Voice (Thai).mp3\"\n",
    "\n",
    "# à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸–à¸­à¸”à¸„à¸§à¸²à¸¡\n",
    "result = transcribe(audio_file_path, device=\"cuda\")\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "transcribed_text1 = result['text']\n",
    "print(f\"à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸–à¸­à¸”à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰: {transcribed_text1.text}\")\n",
    "print(f\"à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: {result['processing_time']:.2f} à¸§à¸´à¸™à¸²à¸—à¸µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a6efcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒªï¸ Loading Typhoon ASR model on CUDA...\n",
      "[NeMo I 2025-12-07 00:02:46 mixins:184] Tokenizer SentencePieceTokenizer initialized with 2048 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-12-07 00:02:47 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/stt_th_conformer_transducer_large/prepare_data/typhoon_cleanser/20250814/Split_gg/train_data_typhoon_asr_realtime.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 30.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-12-07 00:02:47 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/data/scbx_testset_manifest.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    max_duration: 30.0\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    \n",
      "[NeMo W 2025-12-07 00:02:47 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-12-07 00:02:47 features:306] PADDING: 0\n",
      "[NeMo I 2025-12-07 00:02:48 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:48 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:49 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:49 save_restore_connector:284] Model EncDecRNNTBPEModel was successfully restored from C:\\Users\\aungl\\.cache\\huggingface\\hub\\models--scb10x--typhoon-asr-realtime\\snapshots\\a14b79d50c788dbdfe559c8a28a9b90153cf3865\\typhoon-asr-realtime.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-12-07 00:02:49 dataloader:743] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token\n",
      "[NeMo W 2025-12-07 00:02:49 dataloader:488] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ™ï¸ Running basic transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸–à¸­à¸”à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰: à¸à¸²à¸£à¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸¡à¸°à¸žà¸£à¹‰à¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸ à¸¡à¸²à¸\n",
      "à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: 0.15 à¸§à¸´à¸™à¸²à¸—à¸µ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = \"Aung Voice2 (Thai).mp3\"\n",
    "\n",
    "# à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸–à¸­à¸”à¸„à¸§à¸²à¸¡\n",
    "result = transcribe(audio_file_path, device=\"cuda\")\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "transcribed_text2 = result['text']\n",
    "print(f\"à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸–à¸­à¸”à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰: {transcribed_text2.text}\")\n",
    "print(f\"à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: {result['processing_time']:.2f} à¸§à¸´à¸™à¸²à¸—à¸µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94c6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒªï¸ Loading Typhoon ASR model on CUDA...\n",
      "[NeMo I 2025-12-07 00:02:51 mixins:184] Tokenizer SentencePieceTokenizer initialized with 2048 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-12-07 00:02:53 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/stt_th_conformer_transducer_large/prepare_data/typhoon_cleanser/20250814/Split_gg/train_data_typhoon_asr_realtime.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 30.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-12-07 00:02:53 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/data/scbx_testset_manifest.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    max_duration: 30.0\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    \n",
      "[NeMo W 2025-12-07 00:02:53 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-12-07 00:02:53 features:306] PADDING: 0\n",
      "[NeMo I 2025-12-07 00:02:54 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:54 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:54 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-12-07 00:02:54 save_restore_connector:284] Model EncDecRNNTBPEModel was successfully restored from C:\\Users\\aungl\\.cache\\huggingface\\hub\\models--scb10x--typhoon-asr-realtime\\snapshots\\a14b79d50c788dbdfe559c8a28a9b90153cf3865\\typhoon-asr-realtime.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-12-07 00:02:55 dataloader:743] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token\n",
      "[NeMo W 2025-12-07 00:02:55 dataloader:488] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ™ï¸ Running basic transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸–à¸­à¸”à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰: à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¸—à¸­à¸‡à¸›à¸­à¸à¸„à¸­à¸ªà¸µà¹€à¸‡à¸´à¸™ à¸„à¸§à¸²à¸¡à¸£à¸±à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¹€à¸à¸¥à¸µà¸¢à¸”à¸Šà¸±à¸‡ à¸ à¸²à¸žà¸¡à¸²à¸¢à¸²à¹à¸«à¹ˆà¸‡à¸‹à¸²à¸à¸¨à¸ž à¹‚à¸Šà¸„à¸Šà¸°à¸•à¸²à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰ à¸ˆà¸‡à¸«à¸²à¸¢à¹„à¸›à¸«à¹ˆà¸§à¸‡à¸ªà¸µà¸—à¸­à¸‡ à¸à¹ˆà¸­à¸™à¸¥à¸­à¸¢à¸¥à¹‰à¸­à¸£à¸–à¸ˆà¸°à¸ªà¸±à¸‡à¸«à¸²à¸£à¹€à¸ˆà¹‰à¸² à¹à¸‹à¹ˆà¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸¸à¹ˆà¸‡à¹‚à¸£à¸ˆà¸™à¹Œ à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸±à¸ à¸„à¹ˆà¸²à¸•à¸­à¸šà¹à¸—à¸™à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰ à¸ˆà¸‡à¸«à¸¡à¸¸à¸™ à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¹€à¸‡à¸´à¸™ à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸„à¸­à¸™à¸µà¹‰à¸¥à¹ˆà¸§à¸‡à¸«à¸¥à¹ˆà¸™ à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸•à¸­à¸™à¸™à¸±à¹‰à¸™à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸à¸”à¸Ÿà¸±à¸‡à¸šà¸—à¹€à¸žà¸¥à¸‡à¸‚à¸­à¸‡à¸¥à¹‰à¸­à¸£à¸– à¸­à¸µà¸à¸à¸²à¸à¸‚à¸­à¸‡à¸à¸²à¸à¸Ÿà¹‰à¸² à¸ˆà¸‡à¸—à¸°à¸¢à¸²à¸™ à¸žà¸£à¹‰à¸­à¸¡à¸šà¸£à¸£à¸—à¸¸à¸à¸„à¸§à¸²à¸¡à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸‚à¸­à¸‡à¹€à¸—à¸žà¸˜à¸´à¸”à¸² à¸à¸²à¸¬à¸´à¸™à¹€à¸™à¹€à¸‹ à¸Ÿà¹‚à¸£à¹€à¸¡à¸¥\n",
      "à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: 0.35 à¸§à¸´à¸™à¸²à¸—à¸µ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = \"Aung Voice3 (Thai).mp3\"\n",
    "\n",
    "# à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸–à¸­à¸”à¸„à¸§à¸²à¸¡\n",
    "result = transcribe(audio_file_path, device=\"cuda\")\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "transcribed_text3 = result['text']\n",
    "print(f\"à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸–à¸­à¸”à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰: {transcribed_text3.text}\")\n",
    "print(f\"à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: {result['processing_time']:.2f} à¸§à¸´à¸™à¸²à¸—à¸µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c640540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸šà¸œà¸¡à¸Šà¸·à¹ˆà¸­à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸ à¸§à¸“à¸´à¸Šà¸Šà¸™à¸±à¸¢ à¸£à¸«à¸±à¸ªà¸«à¸à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¸ªà¸­à¸‡à¹€à¸à¹‰à¸²à¹€à¸ˆà¹‡à¸” à¹€à¸­à¹ˆà¸­ à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œ à¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡à¹€à¸à¹‰à¸² à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸—à¸«à¸²à¸£à¸£à¸²à¸Šà¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n"
     ]
    }
   ],
   "source": [
    "print(transcribed_text1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb1038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸à¸²à¸£à¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸¡à¸°à¸žà¸£à¹‰à¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸ à¸¡à¸²à¸\n"
     ]
    }
   ],
   "source": [
    "print(transcribed_text2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b6e03",
   "metadata": {},
   "source": [
    "à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥ openai/whisper-large-v3-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66917ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. à¸à¸³à¸«à¸™à¸”à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ (GPU à¸«à¸£à¸·à¸­ CPU)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# 2. à¸à¸³à¸«à¸™à¸” model ID\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "# 3. à¸ªà¸£à¹‰à¸²à¸‡ ASR Pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f20e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¸·à¹ˆà¸­ à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸à¸§à¸±à¸™à¸™à¸´à¸Šà¸²à¹ƒà¸™ à¸£à¸«à¸±à¸ª 67070297 à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆ à¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸£à¸£à¸¢à¸²à¸›à¸¥à¸´à¸• à¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡ 9 à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸•à¸«à¸²à¸£à¸£à¹‰à¸²à¸™à¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n"
     ]
    }
   ],
   "source": [
    "# à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸Šà¸·à¹ˆà¸­ 'audio.mp3'\n",
    "audio_file_path = \"Aung Voice (Thai).mp3\"\n",
    "\n",
    "# à¸£à¸±à¸™ Transcription\n",
    "result1 = pipe(audio_file_path,generate_kwargs={\"language\": \"thai\"})\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "print(result1[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9bdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸à¸²à¸£à¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸¡à¸°à¸žà¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸à¹†\n"
     ]
    }
   ],
   "source": [
    "# à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸Šà¸·à¹ˆà¸­ 'audio.mp3'\n",
    "audio_file_path = \"Aung Voice2 (Thai).mp3\"\n",
    "\n",
    "# à¸£à¸±à¸™ Transcription\n",
    "result2 = pipe(audio_file_path,generate_kwargs={\"language\": \"thai\"})\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "print(result2[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a430b",
   "metadata": {},
   "source": [
    "à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥ openai/whisper-large-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce83497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. à¸à¸³à¸«à¸™à¸”à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ (GPU à¸«à¸£à¸·à¸­ CPU)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# 2. à¸à¸³à¸«à¸™à¸” model ID\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "# 3. à¸ªà¸£à¹‰à¸²à¸‡ ASR Pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3becf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¸·à¹ˆà¸­ à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸ à¸§à¸±à¸™à¸™à¸µà¹‰à¸Šà¸²à¸§à¹ƒà¸™ à¸£à¸«à¸±à¸ª à¸«à¸à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œ à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¸ªà¸­à¸‡à¹€à¸à¹‰à¸²à¹€à¸ˆà¹‡à¸” à¸­à¹ˆà¸²à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆ à¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œà¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡à¹€à¸à¹‰à¸² à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸—à¸«à¸²à¸£à¸£à¸²à¸Šà¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n"
     ]
    }
   ],
   "source": [
    "# à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸Šà¸·à¹ˆà¸­ 'audio.mp3'\n",
    "audio_file_path = \"Aung Voice (Thai).mp3\"\n",
    "\n",
    "# à¸£à¸±à¸™ Transcription\n",
    "result1_not_turbo = pipe(\n",
    "    audio_file_path,     \n",
    "    generate_kwargs={\"language\": \"thai\"},\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "print(result1_not_turbo[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab9ca7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸à¸²à¸£à¸£à¸±à¸à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸žà¸£à¹‰à¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸à¸¡à¸²à¸\n"
     ]
    }
   ],
   "source": [
    "# à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸Šà¸·à¹ˆà¸­ 'audio.mp3'\n",
    "audio_file_path = \"Aung Voice2 (Thai).mp3\"\n",
    "\n",
    "# à¸£à¸±à¸™ Transcription\n",
    "result2_not_turbo = pipe(\n",
    "    audio_file_path,     \n",
    "    generate_kwargs={\"language\": \"thai\"},\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "print(result2_not_turbo[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b63f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¸—à¸­à¸‡ à¸›à¸­à¸à¸„à¸­à¸ªà¸µà¹€à¸‡à¸´à¸™à¸„à¸§à¸²à¸¡à¸£à¸±à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¹€à¸à¸¥à¸µà¸¢à¸”à¸Šà¸±à¸‡à¸ à¸²à¸žà¸¡à¸²à¸¢à¸²à¹à¸«à¹ˆà¸‡à¸‹à¸²à¸à¸¨à¸žà¹‚à¸Šà¸„à¸Šà¸°à¸•à¸²à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰à¸ˆà¸‡à¸«à¸²à¸¢à¹„à¸› à¸«à¹ˆà¸§à¸‡à¸ªà¸µà¸—à¸­à¸‡à¸à¹ˆà¸­à¸™à¸¥à¹‰à¸­à¸¢à¸¥à¹‰à¸­à¸£à¸–à¸ˆà¸°à¸ªà¸±à¹ˆà¸‡à¸«à¸²à¸à¹€à¸ˆà¹‰à¸²à¹à¸—à¸£à¹ˆà¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸¸à¹ˆà¸‡à¹‚à¸¥à¸”à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸±à¸à¸‚à¹‰à¸²à¸•à¸­à¸šà¹à¸—à¸™à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰à¸ˆà¸‡à¸«à¸¡à¸¸à¸™ à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¹€à¸‡à¸´à¸™à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸„à¸­à¸™à¸µà¹‰à¸¥à¹ˆà¸§à¸‡à¸«à¸¥à¹ˆà¸™à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸•à¸­à¸™à¸™à¸±à¹‰à¸™à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸à¸™à¸Ÿà¸±à¸‡à¸šà¸—à¹€à¸žà¸¥à¸‡à¸‚à¸­à¸‡à¸¥à¹‰à¸­à¸£à¸–à¸­à¸µà¸à¸à¸²à¸à¸‚à¸­à¸‡à¸à¸²à¸à¸Ÿà¹‰à¸² à¸ˆà¸‡à¸—à¸°à¸¢à¸²à¸™à¸žà¸£à¹‰à¸­à¸¡à¸šà¸£à¸£à¸—à¸¸à¸à¸„à¸§à¸²à¸¡à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸‚à¸­à¸‡à¹€à¸—à¸žà¸˜à¸´à¸”à¸²à¸à¸²à¸¥à¸´à¹€à¸™à¹€à¸‹ à¹‚à¸Ÿà¹€à¸¡à¸¥\n"
     ]
    }
   ],
   "source": [
    "# à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸Šà¸·à¹ˆà¸­ 'audio.mp3'\n",
    "audio_file_path = \"Aung Voice3 (Thai).mp3\"\n",
    "\n",
    "# à¸£à¸±à¸™ Transcription\n",
    "result3 = pipe(\n",
    "    audio_file_path,     \n",
    "    generate_kwargs={\"language\": \"thai\"},\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ\n",
    "print(result3[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb145fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scb10x/typhoon-asr-realtime\n",
      "Aung Voice1 (Thai)-> à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸šà¸œà¸¡à¸Šà¸·à¹ˆà¸­à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸ à¸§à¸“à¸´à¸Šà¸Šà¸™à¸±à¸¢ à¸£à¸«à¸±à¸ªà¸«à¸à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¸ªà¸­à¸‡à¹€à¸à¹‰à¸²à¹€à¸ˆà¹‡à¸” à¹€à¸­à¹ˆà¸­ à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œ à¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡à¹€à¸à¹‰à¸² à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸—à¸«à¸²à¸£à¸£à¸²à¸Šà¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n",
      "\n",
      "openai/whisper-large-v3\n",
      "Aung Voice1 (Thai)-> à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¸·à¹ˆà¸­ à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸ à¸§à¸±à¸™à¸™à¸µà¹‰à¸Šà¸²à¸§à¹ƒà¸™ à¸£à¸«à¸±à¸ª à¸«à¸à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œ à¹€à¸ˆà¹‡à¸”à¸¨à¸¹à¸™à¸¢à¹Œà¸ªà¸­à¸‡à¹€à¸à¹‰à¸²à¹€à¸ˆà¹‡à¸” à¸­à¹ˆà¸²à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆ à¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œà¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡à¹€à¸à¹‰à¸² à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸—à¸«à¸²à¸£à¸£à¸²à¸Šà¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n",
      "\n",
      "openai/whisper-large-v3-turbo\n",
      "Aung Voice1 (Thai)-> à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¸·à¹ˆà¸­ à¸™à¸²à¸¢à¸­à¸­à¸‡à¸£à¸±à¸à¸§à¸±à¸™à¸™à¸´à¸Šà¸²à¹ƒà¸™ à¸£à¸«à¸±à¸ª 67070297 à¹€à¸£à¸µà¸¢à¸™à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆ à¸„à¸“à¸°à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ à¸ªà¸²à¸‚à¸²à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸›à¸£à¸£à¸¢à¸²à¸›à¸¥à¸´à¸• à¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸žà¸£à¸°à¸ˆà¸­à¸¡ 9 à¹€à¸ˆà¹‰à¸²à¸„à¸¸à¸“à¸•à¸«à¸²à¸£à¸£à¹‰à¸²à¸™à¸à¸£à¸°à¸šà¸±à¸‡à¸„à¸£à¸±à¸š\n"
     ]
    }
   ],
   "source": [
    "print(\"scb10x/typhoon-asr-realtime\")\n",
    "print(\"Aung Voice1 (Thai)->\",transcribed_text1.text)\n",
    "print()\n",
    "print(\"openai/whisper-large-v3\")\n",
    "print(\"Aung Voice1 (Thai)->\",result1_not_turbo[\"text\"])\n",
    "print()\n",
    "print(\"openai/whisper-large-v3-turbo\")\n",
    "print(\"Aung Voice1 (Thai)->\",result1[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ddeb9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scb10x/typhoon-asr-realtime\n",
      "Aung Voice2 (Thai)-> à¸à¸²à¸£à¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸¡à¸°à¸žà¸£à¹‰à¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸ à¸¡à¸²à¸\n",
      "\n",
      "openai/whisper-large-v3\n",
      "Aung Voice2 (Thai)-> à¸à¸²à¸£à¸£à¸±à¸à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸žà¸£à¹‰à¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸à¸¡à¸²à¸\n",
      "\n",
      "openai/whisper-large-v3-turbo\n",
      "Aung Voice2 (Thai)-> à¸à¸²à¸£à¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§ à¸¡à¸µà¸«à¸¡à¸²à¸¡à¸°à¸žà¸²à¸§à¸•à¸±à¸§à¸«à¸™à¸¶à¹ˆà¸‡à¸™à¹ˆà¸²à¸£à¸±à¸à¸¡à¸²à¸à¹†\n"
     ]
    }
   ],
   "source": [
    "print(\"scb10x/typhoon-asr-realtime\")\n",
    "print(\"Aung Voice2 (Thai)->\",transcribed_text2.text)\n",
    "print()\n",
    "print(\"openai/whisper-large-v3\")\n",
    "print(\"Aung Voice2 (Thai)->\",result2_not_turbo[\"text\"])\n",
    "print()\n",
    "print(\"openai/whisper-large-v3-turbo\")\n",
    "print(\"Aung Voice2 (Thai)->\",result2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06810187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scb10x/typhoon-asr-realtime\n",
      "Aung Voice3 (Thai)-> à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¸—à¸­à¸‡à¸›à¸­à¸à¸„à¸­à¸ªà¸µà¹€à¸‡à¸´à¸™ à¸„à¸§à¸²à¸¡à¸£à¸±à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¹€à¸à¸¥à¸µà¸¢à¸”à¸Šà¸±à¸‡ à¸ à¸²à¸žà¸¡à¸²à¸¢à¸²à¹à¸«à¹ˆà¸‡à¸‹à¸²à¸à¸¨à¸ž à¹‚à¸Šà¸„à¸Šà¸°à¸•à¸²à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰ à¸ˆà¸‡à¸«à¸²à¸¢à¹„à¸›à¸«à¹ˆà¸§à¸‡à¸ªà¸µà¸—à¸­à¸‡ à¸à¹ˆà¸­à¸™à¸¥à¸­à¸¢à¸¥à¹‰à¸­à¸£à¸–à¸ˆà¸°à¸ªà¸±à¸‡à¸«à¸²à¸£à¹€à¸ˆà¹‰à¸² à¹à¸‹à¹ˆà¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸¸à¹ˆà¸‡à¹‚à¸£à¸ˆà¸™à¹Œ à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸±à¸ à¸„à¹ˆà¸²à¸•à¸­à¸šà¹à¸—à¸™à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰ à¸ˆà¸‡à¸«à¸¡à¸¸à¸™ à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¹€à¸‡à¸´à¸™ à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸„à¸­à¸™à¸µà¹‰à¸¥à¹ˆà¸§à¸‡à¸«à¸¥à¹ˆà¸™ à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸•à¸­à¸™à¸™à¸±à¹‰à¸™à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸à¸”à¸Ÿà¸±à¸‡à¸šà¸—à¹€à¸žà¸¥à¸‡à¸‚à¸­à¸‡à¸¥à¹‰à¸­à¸£à¸– à¸­à¸µà¸à¸à¸²à¸à¸‚à¸­à¸‡à¸à¸²à¸à¸Ÿà¹‰à¸² à¸ˆà¸‡à¸—à¸°à¸¢à¸²à¸™ à¸žà¸£à¹‰à¸­à¸¡à¸šà¸£à¸£à¸—à¸¸à¸à¸„à¸§à¸²à¸¡à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸‚à¸­à¸‡à¹€à¸—à¸žà¸˜à¸´à¸”à¸² à¸à¸²à¸¬à¸´à¸™à¹€à¸™à¹€à¸‹ à¸Ÿà¹‚à¸£à¹€à¸¡à¸¥\n",
      "\n",
      "openai/whisper-large-v3\n",
      "Aung Voice3 (Thai)-> à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¸—à¸­à¸‡ à¸›à¸­à¸à¸„à¸­à¸ªà¸µà¹€à¸‡à¸´à¸™à¸„à¸§à¸²à¸¡à¸£à¸±à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¹€à¸à¸¥à¸µà¸¢à¸”à¸Šà¸±à¸‡à¸ à¸²à¸žà¸¡à¸²à¸¢à¸²à¹à¸«à¹ˆà¸‡à¸‹à¸²à¸à¸¨à¸žà¹‚à¸Šà¸„à¸Šà¸°à¸•à¸²à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰à¸ˆà¸‡à¸«à¸²à¸¢à¹„à¸› à¸«à¹ˆà¸§à¸‡à¸ªà¸µà¸—à¸­à¸‡à¸à¹ˆà¸­à¸™à¸¥à¹‰à¸­à¸¢à¸¥à¹‰à¸­à¸£à¸–à¸ˆà¸°à¸ªà¸±à¹ˆà¸‡à¸«à¸²à¸à¹€à¸ˆà¹‰à¸²à¹à¸—à¸£à¹ˆà¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸¸à¹ˆà¸‡à¹‚à¸¥à¸”à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸à¹à¸«à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¸£à¸±à¸à¸‚à¹‰à¸²à¸•à¸­à¸šà¹à¸—à¸™à¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸™à¸µà¹‰à¸ˆà¸‡à¸«à¸¡à¸¸à¸™ à¸¥à¹‰à¸­à¸£à¸–à¸ªà¸µà¹€à¸‡à¸´à¸™à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸„à¸­à¸™à¸µà¹‰à¸¥à¹ˆà¸§à¸‡à¸«à¸¥à¹ˆà¸™à¸ˆà¸™à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¸•à¸­à¸™à¸™à¸±à¹‰à¸™à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸à¸™à¸Ÿà¸±à¸‡à¸šà¸—à¹€à¸žà¸¥à¸‡à¸‚à¸­à¸‡à¸¥à¹‰à¸­à¸£à¸–à¸­à¸µà¸à¸à¸²à¸à¸‚à¸­à¸‡à¸à¸²à¸à¸Ÿà¹‰à¸² à¸ˆà¸‡à¸—à¸°à¸¢à¸²à¸™à¸žà¸£à¹‰à¸­à¸¡à¸šà¸£à¸£à¸—à¸¸à¸à¸„à¸§à¸²à¸¡à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸‚à¸­à¸‡à¹€à¸—à¸žà¸˜à¸´à¸”à¸²à¸à¸²à¸¥à¸´à¹€à¸™à¹€à¸‹ à¹‚à¸Ÿà¹€à¸¡à¸¥\n"
     ]
    }
   ],
   "source": [
    "print(\"scb10x/typhoon-asr-realtime\")\n",
    "print(\"Aung Voice3 (Thai)->\",transcribed_text3.text)\n",
    "print()\n",
    "print(\"openai/whisper-large-v3\")\n",
    "print(\"Aung Voice3 (Thai)->\",result3[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team_Project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
